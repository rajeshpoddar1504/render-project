dynamodb: managed NoSQL db, optimized for performace at scale.
key value lookup store
need to provide primary key to find corresponding value

additional nodes are added to increase the capacity
high availability & durability
Ideal for applications with known access patterns
Access through API/ORMs and authorized through IAM
Integrates will with other AWS services
cost effective usage based payment model

------------------------------------------------------
Core Concepts:
Tables,Items,Attributes,Indexes
Tables are a collection of Items
Items are collections of Attributes,key/value pairs

Global secondary Index: 
-------------------------------------------------------

Here are the answers to your questions:

---

### **1. What is DynamoDB, and how does it differ from traditional databases?**

**DynamoDB** is a fully managed NoSQL database service provided by AWS, optimized for applications that require high performance, low latency, and scalability. Unlike traditional relational databases, which use structured schemas and SQL for queries, DynamoDB is schema-less and supports key-value and document data models.

**Differences from traditional databases:**
- **Schema:** DynamoDB is schema-less, whereas relational databases like MySQL enforce a rigid schema.
- **Query Language:** DynamoDB uses a proprietary query system (AWS SDK or API), while traditional databases use SQL.
- **Scaling:** DynamoDB automatically scales based on demand, while traditional databases typically require manual sharding or replication.
- **Indexes:** DynamoDB provides primary keys, partition keys, and global/local secondary indexes for querying, while relational databases use primary keys, foreign keys, and indexes.

---

### **2. What are the key features of DynamoDB?**

- **Fully Managed:** AWS handles provisioning, replication, backups, and scaling.
- **Fast and Low Latency:** Single-digit millisecond response times.
- **Automatic Scaling:** Dynamically adjusts capacity based on traffic.
- **Durability and High Availability:** Built-in replication across multiple availability zones (AZs).
- **NoSQL:** Supports flexible key-value and document data models.
- **Event Streams:** Integrates with DynamoDB Streams to track changes in the database.
- **Global Tables:** Provides multi-region replication for globally-distributed applications.
- **On-Demand and Provisioned Modes:** Flexible throughput capacities to meet changing workloads.
- **Integration with Other AWS Services:** Works seamlessly with Lambda, S3, CloudWatch, and others.

---

### **3. What is the difference between DynamoDB and a relational database like MySQL?**

| **Aspect**               | **DynamoDB**                           | **MySQL**                        |
|--------------------------|----------------------------------------|-----------------------------------|
| **Data Model**           | Schema-less (Key-Value, Document)      | Relational (Tables, Rows, Columns) |
| **Query Language**       | AWS SDK & NoSQL API                    | SQL                              |
| **Scalability**          | Automatically scales horizontally      | Requires manual sharding or replication |
| **Schema**               | Schema-less (flexible attributes)      | Fixed schema (enforced structure) |
| **Performance**          | Fast, predictable latency              | Slower for large, complex datasets |
| **Use Cases**            | Real-time apps, IoT, gaming, caching   | Traditional transactional use cases |
| **Consistency**          | Eventual or strong (configurable)      | Strong consistency by default    |

---

### **4. What are Partition Key and Sort Key in DynamoDB?**

- **Partition Key (Hash Key):**
  - A single attribute used to uniquely identify items in a table.
  - Used to determine the storage partition where the item resides.
  - Must be unique for each item in the table.

- **Sort Key (Range Key):**
  - Optional. Used in conjunction with the partition key to create a composite primary key.
  - Helps sort and organize items with the same partition key.

**Example:**
A table with a partition key `UserID` and sort key `Timestamp` can store multiple items for the same user (partition key), sorted by a timestamp (sort key).

---

### **5. Can you explain how data is stored in DynamoDB?**

In DynamoDB:
1. Data is stored as **tables**, which contain **items** (rows).
2. Each item consists of attributes, stored as key-value pairs.
3. DynamoDB uses a **partition-based architecture**:
   - Items are stored in partitions based on the **partition key**.
   - Partition keys determine data distribution across physical storage nodes.
   - Partitions allow DynamoDB to scale horizontally by adding more storage nodes.

---

### **6. What is an item, and what are attributes in DynamoDB?**

- **Item:** A single record in a DynamoDB table, similar to a row in a relational database. Each item is uniquely identified by the **primary key**.
- **Attributes:** Key-value pairs that make up an item. Attributes can be scalar values (e.g., strings, numbers, booleans) or complex data types (e.g., lists, maps).

**Example:**
If `UserID` is the partition key:
```json
{
  "UserID": 123,
  "Name": "John Doe",
  "Email": "john.doe@example.com",
  "Age": 30
}
```

---

### **7. What is the maximum size of an item in DynamoDB?**

The maximum size of an item in DynamoDB is **400 KB**, including all the attribute names and values for that item.

---

### **8. What is the pricing model for DynamoDB?**

DynamoDB offers two primary pricing models:
1. **Provisioned Capacity:**
   - Pre-allocate read/write capacity units (RCUs/WCUs).
   - Pay based on the allocated capacity, regardless of actual usage.
   - Suitable for consistent, predictable workloads.

2. **On-Demand Mode:**
   - Pay for the exact read and write requests made.
   - Scales automatically with your application's workload.
   - Ideal for unpredictable/unpredictable traffic.

Additional costs:
- Storage: Billed per GB of data stored.
- DynamoDB Streams: Charged per data read request.
- Backup and Restore: Based on the amount of data backed up.
- Global Tables: Multi-region replication incurs extra costs.

---

### **9. What consistency models are supported by DynamoDB?**

DynamoDB supports two consistency models for read operations:
1. **Eventually Consistent Reads (Default):**
   - Data propagation may take some time across all storage partitions.
   - High throughput but may return stale data immediately after a write.

2. **Strongly Consistent Reads:**
   - Guarantees the most up-to-date data.
   - Slightly higher latency compared to eventually consistent reads.

---

### **10. What is the default read consistency for DynamoDB, and how can you change it?**

- The **default read consistency** in DynamoDB is **Eventually Consistent Reads**.
- To change it:
  - Use the API or SDK to specify a Strongly Consistent Read.
  - Example in an API request: Set the `ConsistentRead` parameter to `true`.

===================================================================================
### **1. What are the read and write capacity modes available in DynamoDB?**
DynamoDB provides **two capacity modes**:
1. **Provisioned Capacity Mode:**
   - You manually specify the number of **Read Capacity Units (RCUs)** and **Write Capacity Units (WCUs)** required.
   - Suitable for workloads with predictable traffic patterns.
   - You can use **auto-scaling** to dynamically adjust the capacity.

2. **On-Demand Capacity Mode:**
   - You are charged per read/write request, paying for only what you use.
   - Suitable for applications with unpredictable or spikey traffic.
   - No need to manage RCUs and WCUs; scaling is automatic.

---

### **2. What are Global and Local Secondary Indexes (GSIs/LSIs) in DynamoDB?**
In DynamoDB, indexes allow efficient querying of data by attributes other than the primary key.

1. **Global Secondary Index (GSI):**
   - Allows querying on attributes other than the primary key.
   - A GSI can have a different **partition key** and **sort key** from the base table.
   - GSIs are created at any time, even after table creation.

2. **Local Secondary Index (LSI):**
   - Allows querying based on the same partition key as the base table, but with a different **sort key**.
   - LSIs must be defined during table creation.
   - Limited to a maximum of **5 LSIs per table**.

---

### **3. What is the difference between a Global Secondary Index (GSI) and a Local Secondary Index (LSI)?**

| **Aspect**               | **Global Secondary Index (GSI)**                | **Local Secondary Index (LSI)**               |
|--------------------------|------------------------------------------------|----------------------------------------------|
| **Partition Key**        | Can differ from base table                     | Same as the base table                       |
| **Sort Key**             | Optional; can differ from base table           | Required; must differ from base table        |
| **Creation Time**        | Can be created at any time                     | Must be defined at the time of table creation |
| **Performance Impact**   | Has its own provisioned throughput             | Shares provisioned throughput with the table |
| **Use Case**             | Query with non-primary attributes              | Query with alternate sort key values for the same partition key |

---

### **4. What is DynamoDB Streams, and how can you use it?**

**DynamoDB Streams** is a feature that captures a time-ordered sequence of item-level changes (insert, update, delete) made to a DynamoDB table. The changes are stored in a stream that can be processed by applications.

**Use Cases:**
- Trigger real-time data processing with AWS **Lambda** (e.g., for notifications, log processing).
- Synchronize data between tables or services.
- Create materialized views by consuming stream data.
- Implement change data capture (CDC) patterns.

---

### **5. Explain the concept of Provisioned Throughput in DynamoDB.**

**Provisioned throughput** defines the maximum read and write capacity that a DynamoDB table can handle.

1. **Read Capacity Units (RCU):**
   - 1 RCU = 1 strongly consistent read of up to 4 KB per second, OR 2 eventually consistent reads of up to 4 KB per second.

2. **Write Capacity Units (WCU):**
   - 1 WCU = 1 write of up to 1 KB per second.

You can adjust the throughput to handle varying workloads (manually or using auto-scaling).

---

### **6. How does Auto Scaling work in DynamoDB?**

**Auto Scaling** dynamically adjusts the read and write capacities of a DynamoDB table or index to handle changing workloads.

- **How it works:**
  1. You define a target utilization percentage (e.g., 70%).
  2. DynamoDB automatically adjusts provisioning to maintain this target.
  3. As application traffic increases, DynamoDB increases RCUs/WCUs.
  4. As traffic decreases, DynamoDB scales down to save costs.

- **Benefits:**
  - Avoids over-provisioning or under-provisioning.
  - Maintains consistent performance.

---

### **7. What are DynamoDB partitions? How does DynamoDB handle partitioning of data?**

**Partitions** are distributed storage units on physical nodes that DynamoDB uses to store data. Tables are divided into multiple partitions based on the **partition key**.

1. **Partition Key (Hash Key):**
   - Used to determine the partition where data is stored.
   - Items with the same partition key are stored in the same partition.

2. **Partitioning and Scaling:**
   - DynamoDB automatically partitions the table as the data volume or throughput exceeds the limits of a single partition.
   - Each partition has a fixed capacity limit (e.g., 10 GB storage).
   - For scaling, DynamoDB splits partitions and redistributes the data.

---

### **8. What is DAX (DynamoDB Accelerator), and when would you use it?**

**DynamoDB Accelerator (DAX):**
- A fully managed in-memory cache for DynamoDB.
- Speeds up queries to provide **microsecond** response times.
- Seamlessly integrates with DynamoDB without requiring code changes.

**Use Cases:**
- Applications that require ultra-low latency for repeated read-heavy operations.
- Use DAX to reduce read costs by caching frequently accessed data.
- Ideal for applications like gaming, real-time bidding, and e-commerce.

---

### **9. How does DynamoDB handle single-digit millisecond performance?**

DynamoDB achieves consistent single-digit millisecond performance using several design principles:
1. **Partition-Based Scaling:** Scales horizontally using partitions, distributing data and load.
2. **Fully Managed Infrastructure:** Data is automatically replicated across multiple availability zones (AZs) for low-latency access.
3. **Optimized Storage Layer:** Uses SSD (Solid State Drive) storage for high-speed data retrieval.
4. **Key-Value Data Model:** Eliminates overhead associated with relational databases.
5. **Caching Options (e.g., DAX):** In-memory caching helps reduce response times for frequently read data.

---

### **10. What is an example of a good use case for DynamoDB?**

DynamoDB is ideal for use cases requiring high throughput, scalability, and low latency. Examples include:
1. **IoT Applications:**
   - Handles real-time data ingestion from millions of IoT devices.
   - Example: Smart home systems that log and process sensor data.

2. **E-Commerce Platforms:**
   - Manages product catalogs, inventory, and user sessions.
   - Example: Storing shopping cart items or user order histories.

3. **Gaming Applications:**
   - Tracks player sessions, game state, and leaderboards in real time.

4. **Social Media/Chat Applications:**
   - Handles large-scale unstructured data for posts, likes, and messages.

5. **Real-Time Personalization:**
   - Dynamically provides personalized recommendations for users.

=========================================================================
### **1. What strategies can you use for partition keys to avoid hot partitions in DynamoDB?**

A hot partition occurs when a disproportionate number of requests are routed to the same partition, causing performance bottlenecks. To avoid hot partitions, you can use the following strategies:

1. **Distribute Requests More Uniformly:**
   - Choose partition keys that ensure an even distribution of data across partitions.
   - Avoid using highly skewed or predictable keys, such as timestamps or sequential IDs.

2. **Add Randomization:**
   - Append random numbers or unique suffixes to the partition key. For example, instead of using `UserID` alone, use `UserID_RandomNumber`.

3. **Bucketization/Sharding:**
   - Group items into smaller "buckets" using a composite key (e.g., `Category#BucketNumber`).
   - Example: For time-series data, hash timestamp values into buckets.

4. **Avoid Large Items in a Single Partition:**
   - Ensure that items for a given partition key don’t consume excessive storage.

5. **Use Write Amplification (Indexing):**
   - Introduce duplicate or secondary keys to spread writes across multiple partitions.

---

### **2. How would you design a DynamoDB table for many-to-many relationships?**

Many-to-many relationships can be modeled using **adjacency lists**, where an entity is linked to its related entities using a mapping table. Here’s the approach:

1. Create a table with a composite primary key:
   - **Partition Key:** Represents one entity (e.g., `UserID`).
   - **Sort Key:** Represents the connected entity (e.g., `ItemID`).

2. Store the relationships:
   - Example table structure:
     ```
     PartitionKey (UserID) | SortKey (ItemID) | Relationship Attributes
     user_1                | item_1           | { "relation": "liked", "timestamp": "2023-10-01" }
     user_1                | item_2           | { "relation": "viewed", "timestamp": "2023-10-02" }
     item_1                | user_1           | { "relation": "liked", "timestamp": "2023-10-01" }
     ```

3. Query for connections:
   - Query relationships by using either the `UserID` or the `ItemID` as the partition key.

---

### **3. How does DynamoDB Streams work with AWS Lambda for real-time processing?**

**DynamoDB Streams** captures changes (insert, update, delete) to items in a DynamoDB table. To use Streams for real-time processing with AWS Lambda:

1. **Enable DynamoDB Streams:**
   - At table creation or afterward, enable DynamoDB Streams with **New and Old Image** capture.

2. **Create AWS Lambda Function:**
   - Write a Lambda function to process Stream events (e.g., transform data, replicate it, trigger notifications).

3. **Trigger Lambda:**
   - Use AWS Console or CloudFormation to set DynamoDB Streams as the event source for Lambda.

4. **Event Processing:**
   - Lambda receives a batch of changes as input and processes them.

**Example Use Cases:**
- Updating analytics dashboards.
- Synchronizing data across systems.
- Handling real-time notifications.

---

### **4. What are the different types of querying and scanning operations in DynamoDB? How do they differ?**

1. **Query Operation:**
   - Retrieves items based on a specific **partition key** (and optionally a sort key).
   - Uses indexes or primary keys to narrow down results.
   - Returns fewer items but is more efficient since it accesses a partition directly.

2. **Scan Operation:**
   - Reads **every item** in the table or index.
   - Use filters to refine the results (processed client-side).
   - Less efficient (causes higher latency and consumption) since it scans the entire dataset.

---

### **5. What is the difference between a Query operation and a Scan operation?**

| **Aspect**             | **Query**                                    | **Scan**                                  |
|-----------------------|--------------------------------------------|----------------------------------------|
| **Access**             | Only retrieves items matching the partition key | Reads the entire table or index         |
| **Efficiency**         | Highly efficient, direct partition access | Less efficient, scans whole dataset    |
| **Performance Impact** | Lower cost and latency                     | Higher cost and latency                |
| **Use Case**           | Targeted retrievals (e.g., look up by ID)  | Analytics use cases or bulk reads      |

---

### **6. How would you optimize query performance in DynamoDB?**

1. **Choose the Right Key Design:**
   - Use well-distributed partition keys to avoid hot partitions.

2. **Use Indexes:**
   - Build **Global Secondary Indexes (GSIs)** for querying attributes other than the primary key.

3. **Reduce Scan Operations:**
   - Prefer **Query** operations over **Scan** for retrieving filtered data.

4. **Data Preprocessing:**
   - Precompute frequently accessed data attributes into dedicated tables.

5. **Leverage DAX:**
   - Use DynamoDB Accelerator (DAX) for microsecond caching of query results.

6. **Limit Query Scope:**
   - Paginate results to minimize data loads and response time.

---

### **7. How can you achieve cross-region replication in DynamoDB tables?**

Use **Global Tables** to achieve cross-region replication. Features of Global Tables:
1. **Automatic Multi-Region Replication:**
   - DynamoDB replicates data changes across multiple regions.

2. **Set Up:**
   - When creating a table, enable Global Tables and specify the regions where data should replicate.

3. **Use Cases:**
   - Globally distributed applications.
   - Disaster recovery and high availability.

---

### **8. What are the limits in DynamoDB (e.g., item size, attribute count, etc.)?**

Some key limits include:
1. **Item Size:** The maximum item size is **400 KB**, including attribute names and values.
2. **Attribute Count:** Unlimited number of attributes per item within the 400 KB size limit.
3. **Partition Key Length:** Maximum of **2048 bytes**.
4. **Sort Key Length:** Maximum of **1024 bytes**.

Other limits:
- Maximum of **25 write requests and 25 read requests** per API call (batch operations).
- Tables can have up to **20 global secondary indexes (GSIs)**.
- Local secondary indexes (LSIs) are limited to **5 indexes per table**.

---

### **9. How can you implement TTL (time-to-live) in DynamoDB, and what are its advantages?**

**Time-to-Live (TTL)** automatically deletes expired items from a table based on a specified timestamp attribute.

1. **Enable TTL:**
   - Specify an attribute (e.g., `ExpiresAt`) that stores timestamp data in Unix epoch format.

2. **How It Works:**
   - DynamoDB monitors the attribute and automatically deletes items once their TTL has expired.

3. **Advantages:**
   - Reduces storage costs for expired items.
   - Eliminates manual cleanup processes.
   - Improves query performance by minimizing stored data.

---

### **10. What happens if your DynamoDB table exceeds its provisioned throughput?**

If your DynamoDB table exceeds its provisioned read/write capacity:
1. **Requests Are Throttled:** DynamoDB will reject requests and return **ProvisionedThroughputExceededException** errors.
2. **Impact:**
   - Read/write operations fail until the traffic decreases or capacity increases.
   - Increased latency for some requests.

**Solutions:**
1. Use **Auto Scaling** to dynamically adjust capacity when limits are reached.
2. Switch to **On-Demand Mode** for unpredictable workloads.
3. Use batching to group requests into smaller operations.
=====================================================================
### **1. How would you design a DynamoDB schema for an e-commerce application?**

DynamoDB schema design for an e-commerce application depends on the specific use cases and access patterns. Let's assume we want to support features such as product catalog, user orders, and order details with efficient queries.

#### **Table Design:**
1. **ProductCatalog Table:**
   - **Partition Key:** `ProductID`
   - Attributes: `Category`, `Price`, `Stock`, `Description`, `Brand`, etc.
   - Use cases:
     - Retrieve product details by `ProductID`.
     - Query products by `Category` using a Global Secondary Index (GSI).  
     - GSI Example: `CategoryIndex` (Partition Key: `Category`).

2. **UserOrders Table:**
   - **Partition Key:** `UserID`
   - **Sort Key:** `OrderID`
   - Attributes: `OrderDate`, `Status`, `TotalAmount`, etc.
   - Use cases:
     - Retrieve all orders made by a user.
     - Query recent orders for a user by filtering on `OrderDate`.

3. **OrderDetails Table:**
   - **Partition Key:** `OrderID`
   - **Sort Key:** `ProductID`
   - Attributes: `Quantity`, `Price`, `Subtotal`, etc.
   - Use cases:
     - Retrieve all items in a specific order.
     - Query all products purchased in a given order.

#### **Best Practices:**
- Use one-to-many modeling for orders and order details by designing separate tables and linking them via the `OrderID`.
- Avoid hot partitions by ensuring even distribution of keys (e.g., ensuring Product IDs, User IDs, and Order IDs are uniformly distributed).

#### Example Query Flow:
- Retrieve a user’s orders by querying the `UserOrders` table using the `UserID`.
- Fetch details for a specific order from the `OrderDetails` table by querying with the `OrderID`.

---

### **2. Your application has high traffic, and you're noticing throttling in DynamoDB. What steps would you take to fix this?**

#### **Potential Causes of Throttling:**
1. Exceeding provisioned throughput (RCUs/WCUs).
2. Hot partitions due to uneven key distribution.

#### **Steps to Fix It:**

1. **Enable Auto Scaling:**
   - Set up **auto-scaling** to dynamically adjust provisioned capacity based on traffic.

2. **Switch to On-Demand Mode:**
   - If traffic patterns are unpredictable or spiky, use the **on-demand mode**, where throughput scales automatically.

3. **Redistribute Workload to Avoid Hot Partitions:**
   - Review the schema design to ensure an even distribution of reads/writes across partitions.
   - Use a composite or randomized key strategy to minimize hot partitioning (e.g., append a hashed suffix to partition keys).

4. **Use Global Secondary Indexes (GSIs):**
   - Offload frequent queries on non-primary key attributes by designing GSIs.

5. **Implement Write Batching:**
   - Use batch operations to reduce the frequency of small writes. For example, group writes that can be performed in one API call (`BatchWriteItem`).

6. **Use DynamoDB Accelerator (DAX):**
   - Implement a caching service like DAX to reduce the number of reads to DynamoDB for frequently accessed data.

---

### **3. Describe how you would migrate an existing relational database to DynamoDB.**

Migrating a relational database (RDBMS) to DynamoDB involves the following steps:

#### **1. Analyze the Data Model:**
   - Identify tables, relationships (one-to-many, many-to-many), and query patterns in the relational database.
   - Determine access patterns to optimize DynamoDB schema (since it’s designed around query-driven modeling).

#### **2. Design the DynamoDB Schema:**
   - Replace relational tables with DynamoDB tables.
   - Use key-value pairs, composite primary keys, and indexes to handle relationships.
     - Example: Model many-to-many relationships with mapping tables (e.g., `OrderID` to `ProductID`).

#### **3. Choose Indexing Strategies:**
   - Use **Partition Key** and optional **Sort Key** for the primary key.
   - Design **Global Secondary Indexes (GSIs)** or **Local Secondary Indexes (LSIs)** for alternate query requirements.

#### **4. Use AWS Database Migration Service (DMS):**
   - Migrate data from RDBMS to DynamoDB using DMS.
   - Set up DMS tasks for **continuous replication** (useful for minimizing downtime during migration).

#### **5. Optimize Data Transfer:**
   - Use **Amazon EMR**, **AWS Glue**, or write custom scripts to clean and transform data to fit the DynamoDB schema.

#### **6. Test and Validate:**
   - Test DynamoDB queries and compare results with the original relational database.
   - Validate whether the DynamoDB schema satisfies use cases.

#### Example:
A relational table for orders with a foreign key relationship (`User -> Orders`) would be migrated into two DynamoDB tables:
- `UserOrders` with `UserID` as the Partition Key and `OrderID` as the Sort Key.
- `OrderDetails` with `OrderID` as the Partition Key.

---

### **4. You have a use case that requires complex joins between tables. Would DynamoDB be a good option? Why or why not?**

**DynamoDB is not ideal for use cases requiring complex joins.**

#### **Reasons:**
1. **No Native Join Support:**
   - DynamoDB does not support SQL-like joins between tables natively.
   - Joins must be implemented at the application level, increasing complexity.

2. **Denormalized Design Preferred:**
   - DynamoDB schemas favor **denormalization** and pre-joining data (“one table per access pattern”) to ensure fast, predictable reads.

3. **Increased Costs:**
   - Implementing joins in the application means querying multiple tables and performing data aggregation, which can increase latency and cost.

#### **Alternatives:**
- Use a relational database (e.g., Amazon RDS or Aurora) where joins are part of the query language.
- For NoSQL use cases with joins, consider databases like Amazon Neptune (graph DB) or Elasticsearch.

---

### **5. If your application requires ordering items on multiple fields, how would you design it in DynamoDB?**

Ordering in DynamoDB is handled through **Sort Keys** or through indexing.

#### **Single Sort Key Ordering:**
1. Define a single **Sort Key** for ordering based on one field.
   - Example: In a `UserOrders` table:
     - Partition Key: `UserID`
     - Sort Key: `OrderDate`

   Query results will automatically be ordered by `OrderDate`.

#### **Ordering on Multiple Fields:**
If the application requires ordering on multiple attributes:
1. **Composite Sort Key:**
   - Concatenate multiple fields in a single sort key in a meaningful order.
   - Example:
     - Sort Key: `"TotalAmount#OrderDate"`
     - Query results are ordered primarily by `TotalAmount` and secondarily by `OrderDate`.

2. **Use Global Secondary Index (GSI):**
   - Create a GSI with attributes you want to query and order by.
   - Example:
     - Partition Key: `UserID`
     - Sort Key: `Price` (index).
   - Query for a user’s orders and order them by price.

3. **Post-Processing:**
   - For complex ordering not supported natively, fetch results and sort them programmatically in the application layer.

#### **Schema Example:**
- Table: `ProductCatalog`
  - Partition Key: `Category`
  - Sort Key: `Price#ProductName`  
  - Query Example: Retrieve products in a category, ordered by price.

=======================================================================================
### **1. Write a query in the AWS SDK to fetch all items with a specific Partition Key.**

Here is an example using the **AWS SDK for JavaScript**:

```javascript
// Import the AWS SDK
const AWS = require('aws-sdk');

// Configure DynamoDB
const dynamodb = new AWS.DynamoDB.DocumentClient();

// Query parameters
const params = {
  TableName: 'YourTableName',
  KeyConditionExpression: 'PartitionKey = :partitionKey',
  ExpressionAttributeValues: {
    ':partitionKey': 'YourPartitionValue',
  },
};

// Fetch items using the query operation
dynamodb.query(params, (err, data) => {
  if (err) {
    console.error('Error querying items:', err);
  } else {
    console.log('Items fetched:', data.Items);
  }
});
```

- Replace `YourTableName` and `PartitionKey` with the name of your table and partition key attribute.
- Replace `YourPartitionValue` with the value of the partition key you want to query.

---

### **2. How would you implement pagination in DynamoDB?**

Pagination in DynamoDB can be implemented using the `LastEvaluatedKey` provided by the API.

#### Example:

```javascript
const AWS = require('aws-sdk');
const dynamodb = new AWS.DynamoDB.DocumentClient();

// Query function with pagination
async function fetchItemsPaginated(params) {
  let results = [];
  let lastEvaluatedKey = null;

  do {
    if (lastEvaluatedKey) {
      params.ExclusiveStartKey = lastEvaluatedKey;
    }

    const data = await dynamodb.query(params).promise();
    results = results.concat(data.Items);
    lastEvaluatedKey = data.LastEvaluatedKey; // Set for next iteration

  } while (lastEvaluatedKey);

  return results;
}

// Example usage
const params = {
  TableName: 'YourTableName',
  KeyConditionExpression: 'PartitionKey = :partitionKey',
  ExpressionAttributeValues: {
    ':partitionKey': 'YourPartitionValue',
  },
  Limit: 10, // Limit per page
};

fetchItemsPaginated(params)
  .then(data => console.log('All items:', data))
  .catch(err => console.error('Error:', err));
```

---

### **3. Write a script to create a DynamoDB table with a Global Secondary Index (GSI).**

Here’s an AWS SDK script in JavaScript to create a DynamoDB table with a GSI:

```javascript
const AWS = require('aws-sdk');
const dynamodb = new AWS.DynamoDB();

const params = {
  TableName: 'YourTableName',
  AttributeDefinitions: [
    { AttributeName: 'PartitionKey', AttributeType: 'S' },
    { AttributeName: 'SortKey', AttributeType: 'N' },
    { AttributeName: 'SecondaryKey', AttributeType: 'S' }, // GSI Key
  ],
  KeySchema: [
    { AttributeName: 'PartitionKey', KeyType: 'HASH' },
    { AttributeName: 'SortKey', KeyType: 'RANGE' },
  ],
  ProvisionedThroughput: {
    ReadCapacityUnits: 5,
    WriteCapacityUnits: 5,
  },
  GlobalSecondaryIndexes: [
    {
      IndexName: 'GSI-SecondaryKey',
      KeySchema: [{ AttributeName: 'SecondaryKey', KeyType: 'HASH' }],
      Projection: { ProjectionType: 'ALL' },
      ProvisionedThroughput: {
        ReadCapacityUnits: 5,
        WriteCapacityUnits: 5,
      },
    },
  ],
};

dynamodb.createTable(params, (err, data) => {
  if (err) {
    console.error('Unable to create table:', err);
  } else {
    console.log('Created table:', data.TableDescription);
  }
});
```

This script:
- Creates a table with a `PartitionKey` and `SortKey`.
- Includes a GSI named `GSI-SecondaryKey` that allows you to query by the `SecondaryKey` attribute.

---

### **4. How would you retrieve a single item based on its Partition Key and Sort Key from DynamoDB using the AWS CLI?**

Use the `get-item` operation in the AWS CLI:

```bash
aws dynamodb get-item \
  --table-name YourTableName \
  --key '{"PartitionKey": {"S": "YourPartitionValue"}, "SortKey": {"N": "YourSortKeyValue"}}'
```

- Replace `YourTableName`, `YourPartitionValue`, and `YourSortKeyValue` with your table’s name and key values.
- Note: Assign `S` for string attributes and `N` for number attributes in the key definition.

---

### **5. Explain how to use DynamoDB `BatchWriteItem` for inserting multiple items at once.**

The `BatchWriteItem` operation in DynamoDB allows you to insert or delete up to **25 items** in a single API request.

#### Example Script Using AWS SDK (JavaScript):

```javascript
const AWS = require('aws-sdk');
const dynamodb = new AWS.DynamoDB.DocumentClient();

const params = {
  RequestItems: {
    YourTableName: [
      {
        PutRequest: {
          Item: { PartitionKey: 'Key1', Attribute: 'Value1' },
        },
      },
      {
        PutRequest: {
          Item: { PartitionKey: 'Key2', Attribute: 'Value2' },
        },
      },
      {
        PutRequest: {
          Item: { PartitionKey: 'Key3', Attribute: 'Value3' },
        },
      },
    ],
  },
};

dynamodb.batchWrite(params, (err, data) => {
  if (err) {
    console.error('Error in BatchWriteItem:', err);
  } else {
    console.log('Batch write successful:', data);
  }
});
```

**Notes:**
- Each table can have up to 25 write requests (PutRequest or DeleteRequest).
- The combined item size of a single batch cannot exceed **16 MB**.

---

### **6. Best Practices & Trade-offs**

#### **a. Best Practices for Designing a DynamoDB Schema**
1. **Design for Access Patterns**:
   - Identify and model access patterns upfront.
   - Use one table per access pattern by denormalizing data where needed.
2. **Choose Efficient Partition Keys:**
   - Ensure partition keys distribute data evenly to avoid hot partitions.
3. **Use Composite Keys:**
   - Combine `Partition Key` and `Sort Key` to model one-to-many and many-to-many relationships.
4. **Indexing:**
   - Use **Global Secondary Indexes (GSIs)** for querying attributes other than the primary key.
5. **Data Pre-Aggregation:**
   - Store pre-aggregated or computed values for common queries to reduce latency.

---

#### **b. Trade-offs Between Eventual Consistency and Strong Consistency**

| **Aspect**              | **Eventual Consistency**                          | **Strong Consistency**                           |
|--------------------------|--------------------------------------------------|-------------------------------------------------|
| **Latency**              | Faster                                           | Higher Latency                                  |
| **Availability**         | Higher availability                              | May block during high-load scenarios            |
| **Read Precision**       | May return stale data (slightly out-of-date)     | Always returns the latest consistent data       |
| **Cost**                 | Lesser read capacity needed                     | More read capacity units (RCUs) for strong reads |

---

#### **c. When Would You Choose DynamoDB Over Other Databases Like Aurora or Redshift?**

1. **When to Choose DynamoDB:**
   - Low-latency, high-traffic applications (e.g., gaming, IoT, e-commerce).
   - Serverless applications that require auto-scaling.
   - Use cases requiring a NoSQL model (key-value/document store).
   - Applications with predictable access patterns.

2. **When to Choose Aurora/Redshift:**
   - Aurora: If a relational database with SQL querying is needed.
   - Redshift: For complex analytics, reporting, and data warehouse requirements.

---

#### **d. Pros & Cons of On-Demand Capacity Mode:**

**Benefits:**
- Automatic scaling for unpredictable workloads.
- No need to manage RCUs/WCUs manually.
- Cost-effective for applications with low or variable traffic.

**Potential Downsides:**
- Higher operational costs for sustained high-traffic workloads compared to provisioned capacity mode.
- No control over capacity allocation, which might not suit all use cases.

---

#### **e. Techniques to Reduce Costs in DynamoDB for High-Traffic Applications:**
1. **Optimize Schema Design:**
   - Pre-aggregate and store denormalized data to avoid inefficient queries.
2. **Use Auto Scaling:**
   - Dynamically scale throughput based on traffic patterns.
3. **Caching:**
   - Use DynamoDB Accelerator (DAX) to reduce read costs by caching frequently accessed data.
4. **Reduce Unnecessary Scans:**
   - Use Query instead of Scan for more efficient data retrieval.
5. **Batch Operations:**
   - Use batch writes and reads to process multiple items efficiently.
6. **TTL (Time-to-Live):**
   - Automatically remove stale or unnecessary data to save storage costs.

